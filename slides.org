#+TITLE: Shaders = Lazy Images, F-Reps = Lazy Geometry.
#+DATE: 2018-06-12
#+AUTHOR: Chris Hodapp

# (load-library "ox-reveal")

* Introduction
  - Graphics were what first interested me in computers.
    - Dazzle
    - DOOM
    - POV-Ray, PolyRay
    - Toy Story?
  - ...and then sort of what led me to FP.
    - Generating images pixel-by-pixel
    - C, SDL, framebuffers
    - Shaders

#+BEGIN_NOTES
  - Can demo Dazzle here in DOSBOX
  - XaOS?
  - Doom screenshot?
  - The FP stuff: Lisp for macros, Scala for an EDSL
#+END_NOTES

** Motivation

   - Normal CincyFP focus:
     - functional paradigm in contrast to imperative
     - best practices & design for software
   - Focus in this talk: Examples from graphics rendering that are
     from a different angle.
   - i.e. FP methods not as an alternative to imperative methods - but
     alternative to "static" data, by representing that data as an
     algorithm for generating it.

#+BEGIN_NOTES
#+END_NOTES

** Focus
   
   - Graphics shaders
     - /Realtime (i.e. video games)/
       - OpenGL Shading Language (GLSL) & WebGL
       - NVidia Cg (deprecated), Microsoft HLSL
     - /Offline (i.e. production-grade movie CGI)/
       - [[https://github.com/imageworks/OpenShadingLanguage][Open Shading Language]] (OSL) from Sony
       - RenderMan Shading Language from Pixar - now deprecated for
         OSL & DSOs (dynamic shadeops) in C++
   - 3D models as functional representations ([[https://en.wikipedia.org/wiki/Function_representation][F-Reps]])
     - a.k.a. implicit surfaces/isosurfaces

#+BEGIN_NOTES
   - Give good definition of both
   - Yes, OpenGL Shading Language and Open Shading Language are
     completely unrelated (aside from both being shading languages)
#+END_NOTES

* Graphics shaders
  
  - Family of domain-specific languages (typically C/Java-like with
    additional constraints)
  - Ultimately: for writing functions whose input is a point
    in 2D/3D space and whose output is a color value (RGB, RGBA)
    - Sort of a generalization of an image, which also maps points to
      color
  - [[https://github.com/patriciogonzalezvivo/glslViewer][glslViewer]] & [[https://thebookofshaders.com/][Book of Shaders]]

#+BEGIN_NOTES
   - I've sort of glossed over that the inputs also include things
     like camera positions, but they don't really change the fundamentals
   - TODO: Does glslViewer link belong here or later?
#+END_NOTES

** Shader functions

   - Minus a few exceptions (time, other parameters, image inputs),
     these are pure functions that run separately on each element -
     typically a pixel or texel
     - No side effects.
     - No memory across runs.
     - No communication.

#+BEGIN_NOTES
   - TODO: Shader example from ~glslViewer bunny.frag bunny.vert bunny.pl~
   - Show diffuse shader, ambient, specular (if I can get it)
   - Shaders in "real" usage can be sort of arcane...
#+END_NOTES

** Shader functions

   - Why: Shaders must be able to run deterministically and in
     parallel across many elements (typically pixels or texels).
     - Movie CGI: Distributed across whole cluster
     - Video games: Run in parallel on GPU
   - Almost all of you now have several devices with dedicated silicon
     for handling shaders and a compiler for GLSL

#+BEGIN_NOTES
  - This is also why CUDA & OpenCL exist
  - Short, mostly-inaccurate history:
    - Custom render engines in software (Doom, Quake, Descent)
    - Hardware rendering for pushing triangles
    - Fixed hardware pipelines...
    - More flexible hardware pipeines......
    - ?????
    - Now: Almost every computer, phone, tablet has a stream processor
      orders of magnitudes faster than the CPU, and programmable in
      (at minimum) OpenGL Shading Language
#+END_NOTES

** Examples...
   [[https://upload.wikimedia.org/wikipedia/commons/6/6b/Phong_components_version_4.png]]

** Perlin noise & simplex noise

    - [[https://dl.acm.org/citation.cfm?id=325247][Ken Perlin: An image synthesizer (1985)]]
    - Well-behaved, deterministic, fast randomness
    - Continuous, smooth, limited frequency range, arbitrary number of
      dimensions
    - Example I'm showing: https://github.com/ashima/webgl-noise

 #+BEGIN_NOTES
   - Emerged right around the same time as REYES & RenderMan Shading
     Language
   - Give some incentive for its creation
   - Show noise3D.frag
 #+END_NOTES

** Upside

   - Technical constraints led to FP approaches - but these approaches
     brought other benefits:
     - Very lightweight representation (versus stored images), even
       for complex "natural" textures
     - Can be sampled at arbitrary resolution
     - Independent from underlying renderer
   - It's still an image composition method/genre on its own,
     e.g. http://conal.net/papers/functional-images/ (yes, Conal
     Elliott)

 #+BEGIN_NOTES
   - I am cheating slightly since some of these benefits are from
     procedural expression, and that it's FP-ish is irrelevant
   - Hold all of these 2D transformations in mind
 #+END_NOTES

* Geometry, Shapes, Models

  - Representation depends heavily on requirements...
    - Is shape raytraced or scanline rendered?
    - Facetized to arbitrary precision? (e.g. RenderMan)
    - Numerically exact? (3D CAD/CAM)
    - Sparse vs. dense?  How compact must it be?
    - Did 3D measurements or simulations produce it?  (MRI, CT scan,
      laser scan, Finite Element Analysis)
    - What transformations should be easy?
    - Must it be a manifold with interior/exterior?
    - Implicit vs. explicit?
  - See also:
    http://www.cs.toronto.edu/~jacobson/images/geometry-processing-in-the-wild-alec-jacobson.pdf

#+BEGIN_NOTES
  - Geometry & shaders don't have sharp boundaries.  In RenderMan and
    in more modern OpenGL, shaders influence geometry directly.
  - However, shaders evolved to handle all sorts of less "faked"
    lighting
  - TODO: Visualizations? POV-Ray?
#+END_NOTES

** Examples

   - Meshes, voxels
   - Point clouds
   - Analytic primitives, closed-form intersection formulas
   - NURBS
   - Isosurfaces, SDFs
   - [[http://gigavoxels.inrialpes.fr/][GigaVoxels]]

** Example: Triangle mesh

   https://upload.wikimedia.org/wikipedia/commons/f/fb/Dolphin_triangle_mesh.png

** Example: Point clouds

   [[https://upload.wikimedia.org/wikipedia/commons/4/4c/Point_cloud_torus.gif]]

** Example: Voxels

   https://upload.wikimedia.org/wikipedia/commons/4/47/Ribo-Voxels.png

** Example: NURBS

   https://upload.wikimedia.org/wikipedia/commons/e/ea/NURBS_3-D_surface.gif

** Raytracing

  - As name implies: traces camera rays from each pixel into the
    scene.
  - Renders anything with a ray intersection formula.
  - Handles things like reflection, refraction, translucency with no
    faking required.

#+BEGIN_NOTES
  - A lot of the clever use of shaders in RenderMan was to work around
    limitations of scanline rendering (as REYES was heavily oriented
    around, rather than raytracing).
  - However, shaders evolved to handle all sorts of less "faked"
    lighting
#+END_NOTES

** Raytracing

   https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Ray_trace_diagram.svg/875px-Ray_trace_diagram.svg.png

** POV-Ray example

   https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Glasses_800_edit.png/1280px-Glasses_800_edit.png

** POV-Ray, Clojure, Twitter, and Heroku?

   - [[https://twitter.com/nailpolishbot][Nail polish bot]]

** Limitations on shapes/primitives

   - This analytical approach is elegant and all, but...
   - What if you don't have a ray intersection formula?
     - Isosurfaces, SDFs
     - Displacement
     - Fractals
   - Approximate with meshes/NURBS?
#+BEGIN_NOTES
   - Next slide - raymarching - is one answer to this
#+END_NOTES

* Raymarching & F-Reps

  - Raymarching is sort of like raytracing - but intersection is
    iterative & approximate rather than analytical:
    - Surfaces that are a pain - no analytic intersection formula
    - Things with no surfaces - e.g. volumes with varying density
    - Things with infinitely detailed surfaces - e.g. fractals
  - [[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.438.4926&rep=rep1&type=pdf][Ken Perlin again: Hypertexture (1989)]]
  - [[https://www.researchgate.net/publication/234777691_Ray_tracing_deterministic_3-D_fractals][John C. Hart: Ray tracing deterministic 3D fractals (1989)]]

#+BEGIN_NOTES
  - TODO: Show some examples of these (maybe both fractals and
    volumes)
#+END_NOTES

** Isosurfaces

   - As far as we care: isosurfaces are functions $f(x,y,z)$
     representing a 3D surface in which, for 3D point $(x,y,z)$:
     - $f(x,y,z) = 0$ on surface
     - $f(x,y,z) > 0$ outside of surface
     - $f(x,y,z) < 0$ inside of surface
   - Simple example: A sphere of radius $R$ centered at $(0,0,0)$ is
     $$f(x,y,z) = (x^2+y^2+z^2)-R^2$$

** I'm sorry. I didn't make the names.

   - *Isosurface = [[https://en.wikipedia.org/wiki/Function_representation][F-Rep]] = implicit surface = level surface*
   - *Signed distance estimate = signed distance bound = unbounding volume (?)*
     - Isosurface with more rules: $(x,y,z)$ is distance
       $\geq |f(x,y,z)|$ away from nearest point on surface
   - *SDF = signed distance field = signed distance function*
     - Signed distance bound (thus, isosurface also) with more rules:
       $(x,y,z)$ is distance $|f(x,y,z)|$ away from nearest point on
       surface.
   - *Hypertexture* also refers to this, except for when it doesn't.

** I'm sorry, part 2

   - Any [[https://en.wikipedia.org/wiki/Lipschitz_continuity][Lipschitz continuous]] isosurface can be turned to a signed
     distance bound, which is Left As An Exercise To the Reader(tm) or
     just go read [[http://mathinfo.univ-reims.fr/IMG/pdf/hart94sphere.pdf][Sphere Tracing: A Geometric Method for the
     Antialiased Ray Tracing of Implicit Surfaces]] by John C. Hart
   - Let's all just agree to ignore unsigned distance
     bounds/fields/functions/estimates because I've completely stopped
     caring at this point

** Why bother?
   - Similar handy things as shaders, plus 3D stuff:
     - Domain transformations (see: [[http://iquilezles.org/www/articles/distfunctions/distfunctions.htm][Modeling with distance functions]])
     - CSG
   - Blah blah blah mathematical elegance
   - Because it's cool, mostly
   - With *sphere tracing* (or *distance estimation*) you can render
     these in realtime on the GPU

#+BEGIN_NOTES
  - Link to some of IQ's shadertoy or pouet examples
  - Show libfive examples
  - Íñigo Quílez: [[http://www.iquilezles.org/www/material/nvscene2008/rwwtt.pdf][Rendering Worlds with Two Triangles]]
  - Explain/show what domain transformations are
#+END_NOTES

** Why bother? (2)

   - SDFs don't have to be analytical/functional. They can be
     approximate numerical representations, e.g. a sampling over a
     3D grid
   - https://github.com/xx3000/mTec - "Efficient Rendering with
     Distance Fields"
   - KinectFusion used Truncated SDFs to store geometry on GPU and
     efficiently work with it

** How is this used in practice?
   
   - It's sorta not, unless you count:
     - Demoscene (e.g. [[https://www.pouet.net/][pouët.net]]), which is sorta defined by its
       impractical size constraints
       - e.g. https://www.pouet.net/prod.php?which=71778
     - [[https://fractalforums.org/][Fractalforums]], which is sorta defined by a love of math and
       fractals
     - I don't know, it might be used for rendering voxels or
       something
   - Just shut up, it's neat

** How is this used in practice? (2)

   - Commercially: [[https://ntopology.com/][nTopology]] CAD is based on SDFs (thanks Jeff Burdick
     for showing me)
   - [[http://www.implicitcad.org/][ImplicitCAD]] language (sort of like OpenSCAD)
   - [[https://github.com/curv3d/curv][curv]] language by Doug Moen
   - [[https://docs.racket-lang.org/ruckus/index.html][Ruckus]] "Procedural CAD for Weirdos" (Racket Scheme based)
   - [[https://libfive.com/][libfive]] (Guile Scheme based)
     - [[https://github.com/mkeeter/antimony][antimony]], [[https://www.mattkeeter.com/projects/ao/][Ao]] - same author (Matt Keeter)
   - [[https://en.wikipedia.org/wiki/HyperFun][HyperFun]]

#+BEGIN_NOTES
   - http://www.implicitcad.org/editor - demo in browser
#+END_NOTES

* The point of all this

  - Shaders, isosurfaces, hypertextures, and possibly some other
    representations share one property: they are functions which
    always explicitly take *space* as their input.
    - They can be composed with any function that maps space to space.

#+BEGIN_NOTES
  - https://mrl.nyu.edu/~perlin/doc/hypertexture/
#+END_NOTES

** Laziness
  - Shaders are basically /lazy images/
  - Isosurfaces are basically /lazy geometry/
  - They can encode - in theory - image and geometry data that is
    infinite in size or in detail
    - ...and incur cost only for the part that is needed
    - ...assuming it can actually be encoded meaningfully as a
      function
  - As an extreme example of that, see: [[http://blog.hvidtfeldts.net/index.php/2011/06/distance-estimated-3d-fractals-part-i/][Syntopia: Distance Estimated
    3D Fractals]]
    - Distance bounds can be made for both [[https://en.wikipedia.org/wiki/Iterated_function_system][IFS]] and escape-time
      fractals

** Representation

- Both sort of replaced *data* with *functions*.
  - Instead of triangle meshes: basic shapes + transformations
  - Instead of image maps: compositions of noise functions
- Both used functional approaches as practical solutions.

* Other Links

  - [[https://github.com/patriciogonzalezvivo/glslViewer][glslViewer]] & [[https://thebookofshaders.com/][Book of Shaders]]
  - Literally everything from [[http://iquilezles.org/www/index.htm][Íñigo Quílez]]
  - [[http://blog.hvidtfeldts.net/index.php/2011/06/distance-estimated-3d-fractals-part-i/][Syntopia: Distance Estimated 3D Fractals]] & [[https://syntopia.github.io/Fragmentarium/][Fragmentarium]] / [[https://github.com/3Dickulus/FragM][FragM]]
  - ShaderToy
  - https://hodapp87.github.io/cs6460_project/

* Final notes
  - Twitter: @hodapp87
  - GitHub: https://github.com/hodapp87
  - Slides proudly generated with Emacs & [[https://github.com/yjwen/org-reveal][org-reveal]]
