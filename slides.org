#+TITLE: Graphics Shaders as (sort of) Functional Programming
#+DATE: 2018-06-12
#+AUTHOR: Chris Hodapp

* Introduction
  - Graphics were what first interested me in computers.
    - Dazzle
    - DOOM
    - POV-Ray, PolyRay
    - Toy Story?
  - ...and then sort of what led me to FP.
    - Generating images pixel-by-pixel
    - C, SDL, framebuffers
    - Shaders

#+BEGIN_NOTES
  - Can demo Dazzle here in DOSBOX
  - XaOS?
  - Doom screenshot?
  - The FP stuff: Lisp for macros, Scala for an EDSL
#+END_NOTES

* Movies & 3D CGI

  - Various practical problems:
    - Raytracing is slow
    - Scanline rendering is faster, but looks bad
    - Image are sort of bulky and inelegant

#+BEGIN_NOTES
  - Have a good definition/example of scanline rendering
#+END_NOTES

** Pixar & RenderMan

   - Facetize everything to triangles < 1 pixel
   - RenderMan Shading Language
   - Pre-compute & pre-shade
   - Distributes easily across a cluster
   - [[https://www.youtube.com/watch?v=ffIZSAZRzDA][Tin Toy (1988)]]: First CGI film to win Oscar
   - Toy Story (1995): First full-length CGI film

** Perlin noise

   - [[https://dl.acm.org/citation.cfm?id=325247][Ken Perlin: An image synthesizer (1985)]]
   - Well-behaved, deterministic, fast randomness

#+BEGIN_NOTES
  - Emerged right around the same time as REYES & RenderMan Shading
    Language
  - What can I show with Perlin noise?
#+END_NOTES

** The point...

- Both sort of replaced *data* with *functions*.
  - Instead of triangle meshes: basic shapes + transformations
  - Instead of image maps: compositions of noise functions
- Both used functional approaches as practical solutions.

* 3D Video Games
  - Short, mostly-inaccurate history:
    - Custom render engines in software (Doom, Quake, Descent)
    - Hardware rendering for pushing triangles
    - Fixed hardware pipelines...
    - More flexible hardware pipelines......
    - ?????
    - Now: Almost every computer, phone, tablet has a stream processor
      orders of magnitudes faster than the CPU, and programmable in
      (at minimum) OpenGL Shading Language

#+BEGIN_NOTES
  - A parallel track focused more on realtime
  - They inherited most of the limitations of scanline rendering
#+END_NOTES

* Shaders

  - These were the eventual result for both offline rendering
    (i.e. movie CGI) and realtime (i.e. video games).

#+BEGIN_NOTES
  - Both realtime and offline shaders have this 'functional' nature
  - Realtime: Limitations in order to allow parallel scheduling
  - Offline: Limitations in order to allow distributed use
  - Both benefit from very little "global" data and synchronization
    (no textures, just coordinates and small algorithms)
  - Show off some glslViewer examples here?
#+END_NOTES

* Raytracing

  - As name implies: traces camera rays from each pixel into the
    scene.
  - Renders anything with a ray intersection formula.
  - Handles things like reflection, refraction, translucency with no
    faking required.

#+BEGIN_NOTES
  - Ways of composing shapes
  - Ways of composing textures
  - Rendering shapes from equations
  - Show some things I rendered?
  - This can be where I step into ray marchers, I guess
#+END_NOTES

** POV-Ray, Clojure, Twitter, and Heroku?

   - https://github.com/quephird/nail-polish-bot
   - https://twitter.com/nailpolishbot

** Raytracing limitations: Lighting

   - Simple raytracing by itself handles only *direct illumination*.
   - [[https://en.wikipedia.org/wiki/Global_illumination][Global illumination]]
     - Numerical approximations of the [[https://en.wikipedia.org/wiki/Rendering_equation][rendering equation]]
       - [[https://en.wikipedia.org/wiki/Unbiased_rendering][Unbiased]] vs. biased renderers
     - Path tracing
     - Metropolis Light Transport
     - Photon mapping
     - [[https://en.wikipedia.org/wiki/Radiosity_(computer_graphics)][Radiosity]]
     - [[https://en.wikipedia.org/wiki/Ambient_occlusion][Ambient occlusion]]
   - This is a "hard problem"(tm) and I'm ignoring it here.

 #+BEGIN_NOTES
   - Give real-world example of why this is needed
   - Explain why ray tracing by itself doesn't cover this
   - Show examples of some (e.g. AO)
   - http://www.yafaray.org/documentation/userguide/lightingmethods
 #+END_NOTES

** Raytracing limitations: Shapes/primitives

   - What if you want to render a shape that's well-defined...
   - but you don't have a ray intersection formula?
     - Implicit surfaces, isosurfaces, level surfaces
   - Facetize it? Approximate it?
* Raymarching

  - A broad class of iterative methods for rendering:
    - Surfaces that have no analytic intersection formula
    - Things that don't really have surfaces (e.g. volumes with
      varying density)
  - [[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.438.4926&rep=rep1&type=pdf][Ken Perlin again: Hypertexture (1989)]]
  - [[https://www.researchgate.net/publication/234777691_Ray_tracing_deterministic_3-D_fractals][John C. Hart: Ray tracing deterministic 3D fractals (1989)]]
  - [[http://gigavoxels.inrialpes.fr/][GigaVoxels]]?

#+BEGIN_NOTES
#+END_NOTES

** Sphere tracing / distance estimation

  - Ray marching from a *distance field* or *distance estimator*
    function
    - For any point in 3D space, returns a lower bound on the nearest
      distance to the surface/scene/object/whatever
    - Equivalently: For every 3D point /p/, gives the radius of a
      sphere centered at /p/ for which none of the surface is inside
      the sphere. ("Unbounding volumes")
  - [[http://mathinfo.univ-reims.fr/IMG/pdf/hart94sphere.pdf][Sphere Tracing: A Geometric Method for the Antialiased Ray Tracing of Implicit Surfaces]] (John C. Hart)
  - Íñigo Quílez: [[http://www.iquilezles.org/www/material/nvscene2008/rwwtt.pdf][Rendering Worlds with Two Triangles]]

#+BEGIN_NOTES
  - Link to some of IQ's shadertoy or pouet examples
  - Note on Lipschitz continuity
  - Terminology is sort of awful. Hart's sphere tracing paper uses
    "distance bound" for a function giving lower distance bound, and
    "distance function" for exact distance.  His older fractal paper
    uses "distance estimate" rather than "distance bound", I think.
#+END_NOTES

*** Why/how?

    - Because it's cool
    - Because you can do it in realtime on a GPU
    - Blah blah blah mathematical elegance
    - Domain transformations
      - [[http://iquilezles.org/www/articles/distfunctions/distfunctions.htm][Modeling with distance functions]]

#+BEGIN_NOTES
  - Link to some of IQ's shadertoy or pouet examples
#+END_NOTES

* Modern Day
  - Raytracing is now much more common in movie CGI
  - Intel and NVidia are also pushing it for realtime rendering
  - RenderMan Shading Language is now deprecated
  - Sony Pictures ImageWorks: [[https://github.com/imageworks/OpenShadingLanguage][OSL (Open Shading Language)]]
    - [[http://www.blender.org/][Blender]] implements OSL

* Other Links
  - [[https://github.com/patriciogonzalezvivo/glslViewer][glslViewer]] & [[https://thebookofshaders.com/][Book of Shaders]]
  - ShaderToy
  - Basically anything from [[http://iquilezles.org/www/index.htm][Íñigo Quílez]]
  - https://hodapp87.github.io/cs6460_project/

* Final notes
  - Twitter: @hodapp87
  - GitHub: https://github.com/hodapp87
  - Slides proudly generated with Emacs, [[https://github.com/yjwen/org-reveal][org-reveal]], and [[https://revealjs.com/][reveal.js]].
  - FIXME: Other links?
